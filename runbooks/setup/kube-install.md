This concerns setting up the control plane nodes which run a fresh installation of Pi OS. I've already set static IPs for all Raspberry Pis along with hostnames. For my homelab static IPs will ensure stable Kubernetes node communication, ExternalDNS updates, and Harbor registry access without lease expiration disruptions.

## 

## Disable swap and set cgroup drivers for kubelet compatibility.
Kubernetes requires swap disabled by default (NoSwap behavior) for predictable pod scheduling and to avoid OOM issues.
Disable swap and configure the kubelet cgroup driver to systemd on control plane nodes to ensure kubelet compatibility and prevent preflight errors during kubeadm init or kubeadm join

Disable Swap:
```bash
#Temporarily disable all swap
sudo swapoff -a

# Make it permanent by commenting out swap entries in /etc/fstab: 
sudo sed -i '/ swap / s/^/#/' /etc/fstab

# Verify 
free -h #(should show 0 swap)
swapon --show #(no output).​

```


## Installing kube packages on Debian
 ```bash
### 1. Update package list and install required dependencies
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl 

### 2. Download and add the Kubernetes public signing key 
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.34/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

### 3. Add the Kubernetes apt repository
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.34/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list
 
### 4. Update package index and install kubeadm, kubelet, and kubectl
sudo apt-get update
sudo apt-get install -y kubeadm kubelet kubectl
 
### 5. Pin the installed packages to prevent unintended upgrades
```

This one's optional but personally i'd recommend it to avoid any of the installed k8s packages being upgraded automatically, where bad things like breaking changes can happen. Kubernetes components require careful version management because upgrading them could cause compatibility issues or disrupt cluster stability.

```bash
sudo apt-mark hold kubeadm kubelet kubectl
 ```

## Install container runtime (containerd).
Match the kubelet cgroup driver to the container runtime. After deliberating between CRI-O and containerd I went with the latter, there isn't a massive difference between the two as both adhere to the Open Container Initiative. 

Add Containerd Repository
```bash
sudo apt-get update && sudo apt-get install -y ca-certificates curl gpg
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
sudo chmod a+r /etc/apt/keyrings/docker.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
```

The sudo install -m 0755 -d /etc/apt/keyrings command creates the APT keyrings directory securely with specific permissions.​

`sudo install` uses install (instead of mkdir) to create directories atomically (avoids race conditions) and set ownership/permissions in one step.​

It's also more reliable than mkdir -p for package manager scripts.​

`-m 0755` sets permissions: owner (root) rwx (7), group rx (5), others rx (5).​

Directory executable (x) needed for traversal; readable (r) for APT to access GPG keys inside.​

`-d` Creates directory (not a file)—equivalent to mkdir -p but with permissions.​

`/etc/apt/keyrings` Standard Debian/Ubuntu location for modern GPG keys (APT 1.4+ secure keyring format).

`chmod a+r` makes the generated docker.gpg world-readable for APT

If no errors then install containerd with:

```bash
sudo apt-get install -y containerd.io
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml
sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml
sudo systemctl restart containerd
sudo systemctl enable containerd
```

The `sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml` command edits the containerd config file to enable systemd cgroup support.​

`sudo sed` Runs sed (stream editor) with root privileges to modify system config.​

`-i` In-place edit: Modifies the file directly.​

`s/old/new/g` Substitute command: s = substitute, first `/` delimits pattern/replacement. `SystemdCgroup = false` is the search pattern (exact match from default config.toml) and

`SystemdCgroup = true` the replacement text.

`g` global flag (replace ALL occurrences, though there's only one).​

`/etc/containerd/config.toml` Target file generated by containerd config default.​

Why This Change?
Default config: SystemdCgroup = false (uses legacy cgroupfs).​
Kubernetes requires: SystemdCgroup = true to match kubelet's --cgroup-driver=systemd.​
Mismatch causes: Kubelet startup failures with "cgroup driver mismatch" errors.

Verify:

```bash
david@cp1:~ $ sudo ctr version
Client:
  Version:  v2.2.0
  Revision: 1c4457e00facac03ce1d75f7b6777a7a851e5c41
  Go version: go1.24.9

Server:
  Version:  v2.2.0
  Revision: 1c4457e00facac03ce1d75f7b6777a7a851e5c41
  UUID: 5027141d-e52c-4f81-afac-bed17eee3546

david@cp1:~ $ sudo systemctl status containerd
● containerd.service - containerd container runtime
     Loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; preset: enabled)
     Active: active (running) since Wed 2025-11-12 13:22:35 GMT; 2min 25s ago
 Invocation: b1677e14c9234950ba6965c33d006730
       Docs: https://containerd.io
   Main PID: 2777 (containerd)
      Tasks: 10
        CPU: 117ms
     CGroup: /system.slice/containerd.service
```


## Setup kube-vip
For high availability with multiple control planes, I will use kube-vip for virtual IP. I've opted for this over an external load balancer because I don't need strict separation between control plane and load blanacer. Also I want to avoid cloud loadbalancer costs and so prefer a free, open‑source solution I can implement on prem. I also don't want to dedicate a whole raspberry pi to act as a loadbalancer as i prioritise keeping my remaining Pis for worker nodes.

After initializing the first control plane, I can join the second control plane node with the control-plane flag and token.

I've chosen to set up kube-vip now before running `kubeadm init` on cp1 because it creates a static pod manifest that kubeadm will automatically start alongside the control plane components